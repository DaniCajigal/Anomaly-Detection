# -*- coding: utf-8 -*-
"""anomaly-detection-training-iforest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n_PwpQ-y4uQyOeHMzKTzkIm-4_M6Nruq
"""

from zipfile import ZipFile
file_name = "dataset.zip"

with ZipFile(file_name, 'r') as zip:
  zip.extractall()
  print('Done')

!python -m pip install matplotlib
!python -m pip install pandas
!python -m pip install scipy==1.13.1
!python -m pip install scikit-learn==1.5.0

# Print versions
import sys
import sklearn
import scipy
import numpy as np
print('Python', sys.version)
print('Numpy', np.__version__)
print("Scikit-learn:", sklearn.__version__)
print('Scipy', scipy.__version__)

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sn
from os import listdir
from os.path import join
from sklearn.ensemble import IsolationForest
from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix
from scipy.stats import median_abs_deviation
import random

# Definición de variables
dataset_path = 'dataset/'
normal_op_list = ['normal']
anomaly_op_list = ['colectiva']
mixture_op_list = ['puntual']
val_ratio = 0.2
test_ratio = 0.2
raw_scale = 1
sensor_sample_rate = 200
desired_sample_rate = 50
sample_time = 0.64
samples_per_file = 128
max_measurements = int(sample_time * sensor_sample_rate)
downsample_factor = int(samples_per_file / desired_sample_rate)
win_len = int(max_measurements / downsample_factor)

keras_model_name = 'models/autoencoder'
sample_file_name = 'test_samples/normal_anomaly_samples'
rep_dataset_name = 'test_samples/normal_anomaly_test_set'

print('Max measurements per file:', max_measurements)
print('Downsample factor:', downsample_factor)
print('Window length:', win_len)

# Función para crear lista de archivos
def createFilenameList(op_list):
    op_filenames = []
    for target in op_list:
        samples_in_dir = listdir(join(dataset_path, target))
        samples_in_dir = [join(dataset_path, target, sample) for sample in samples_in_dir]
        op_filenames.append(samples_in_dir)
    return [item for sublist in op_filenames for item in sublist]

# Crear listas de nombres de archivos
normal_op_filenames = createFilenameList(normal_op_list)
anomaly_op_filenames = createFilenameList(anomaly_op_list)
print('Number of normal samples:', len(normal_op_filenames))
print('Number of anomaly samples:', len(anomaly_op_filenames))

# Mezclar listas
random.shuffle(normal_op_filenames)
random.shuffle(anomaly_op_filenames)

# Calcular tamaños de conjunto de validación y prueba
val_set_size = int(len(normal_op_filenames) * val_ratio)
test_set_size = int(len(normal_op_filenames) * test_ratio)

# Dividir dataset en train, val y test sets
filenames_val_normal = normal_op_filenames[:val_set_size]
filenames_test_normal = normal_op_filenames[val_set_size:(val_set_size + test_set_size)]
filenames_train = normal_op_filenames[(val_set_size + test_set_size):]

# Imprimir número de muestras en cada conjunto
print('Number of training samples:', len(filenames_train))
print('Number of validation samples:', len(filenames_val_normal))
print('Number of test samples:', len(filenames_test_normal))

# Verificar que las divisiones suman correctamente
assert(len(filenames_train) + len(filenames_val_normal) + len(filenames_test_normal)) == len(normal_op_filenames)

# Función para extraer características
def extract_features(sample, max_measurements=0, scale=1):
    if max_measurements == 0:
        max_measurements = sample.shape[0]
    sample = sample[:max_measurements]
    sample = scale * sample
    features = [median_abs_deviation(sample)]
    return np.array(features).flatten()

# Probar con una muestra
sample = np.genfromtxt(filenames_test_normal[0], delimiter=',')
features = extract_features(sample, max_measurements, scale=raw_scale)
print(features.shape)
print(features)
plt.plot(features)

# Función para crear conjunto de características
def create_feature_set(filenames):
    x_out = []
    for file in filenames:
        sample = np.genfromtxt(file, delimiter=',')
        features = extract_features(sample, max_measurements, raw_scale)
        x_out.append(features)
    return np.array(x_out)

# Crear conjuntos de entrenamiento, validación y prueba
x_train = create_feature_set(filenames_train)
print('Extracted features from training set. Shape:', x_train.shape)
x_val = create_feature_set(filenames_val_normal)
print('Extracted features from validation set. Shape:', x_val.shape)
x_test = create_feature_set(filenames_test_normal)
print('Extracted features from test set. Shape:', x_test.shape)

# Obtener forma de entrada para una muestra
sample_shape = x_train.shape[1:]
print(sample_shape)

# Entrenar el modelo
model = IsolationForest(contamination=0.01, random_state=42)
model.fit(x_train)

# Predecir anomalías en el conjunto de validación
val_predictions = model.predict(x_val)
val_predictions = [0 if p == 1 else 1 for p in val_predictions]
val_labels = [0] * len(x_val)

# Predecir anomalías en el conjunto de prueba
test_predictions = model.predict(x_test)
test_predictions = [0 if p == 1 else 1 for p in test_predictions]
test_labels = [0] * len(x_test)

# Predecir anomalías en el conjunto de prueba anómalo
anomaly_features = create_feature_set(anomaly_op_filenames[:len(x_test)])
anomaly_predictions = model.predict(anomaly_features)
anomaly_predictions = [0 if p == 1 else 1 for p in anomaly_predictions]
anomaly_labels = [1] * len(anomaly_predictions)

# Combinar predicciones y etiquetas
all_predictions = np.concatenate((test_predictions, anomaly_predictions))
all_labels = np.concatenate((test_labels, anomaly_labels))

# Crear y mostrar la matriz de confusión
cm = confusion_matrix(all_labels, all_predictions)
print(cm)
df_cm = pd.DataFrame(cm, index=['normal', 'anomaly'], columns=['normal', 'anomaly'])
plt.figure()
sn.heatmap(df_cm, annot=True)
plt.title('Confusion Matrix')
plt.xlabel('Prediction')
plt.ylabel('Actual')
plt.show()

# Calcular métricas adicionales
precision = precision_score(all_labels, all_predictions)
recall = recall_score(all_labels, all_predictions)
f1 = f1_score(all_labels, all_predictions)

# Imprimir las métricas
print('Precision:', precision)
print('Recall:', recall)
print('F1 Score:', f1)

# Generar e imprimir el informe de clasificación
classification_rep = classification_report(all_labels, all_predictions, target_names=['normal', 'anomaly'])
print(classification_rep)

# Evaluación con el conjunto de datos mixto
mixture_op_filenames = createFilenameList(mixture_op_list)
print('Number of mixture samples:', len(mixture_op_filenames))
mixture_features = create_feature_set(mixture_op_filenames)
print('Extracted features from mixture set. Shape:', mixture_features.shape)

# Predecir anomalías en el conjunto mixto
mixture_predictions = model.predict(mixture_features)
mixture_predictions = [0 if p == 1 else 1 for p in mixture_predictions]
print(mixture_predictions)

"""# Se realiza un entrenamiento solo con muestras normales y ahora se crean conjuntos de test y validación con mezcla de ambas muestras, etiquetadas"""

val_anomaly_size = int(len(filenames_val_normal) * 0.5)  # Por ejemplo, 50% de las muestras de validación serán anómalas
test_anomaly_size = int(len(filenames_test_normal) * 0.5)

# Crear conjuntos de validación y prueba realistas
filenames_val = filenames_val_normal + anomaly_op_filenames[:val_anomaly_size]
filenames_test = filenames_test_normal + anomaly_op_filenames[val_anomaly_size:val_anomaly_size + test_anomaly_size]

# Mezclar los conjuntos
random.shuffle(filenames_val)
random.shuffle(filenames_test)

print('Number of validation samples (mixed):', len(filenames_val))
print('Number of test samples (mixed):', len(filenames_test))


x_val = create_feature_set(filenames_val)
print('Extracted features from validation set. Shape:', x_val.shape)
x_test = create_feature_set(filenames_test)
print('Extracted features from test set. Shape:', x_test.shape)

# Predecir anomalías en el conjunto de validación
val_predictions = model.predict(x_val)
val_anomaly_scores = model.decision_function(x_val)

# Predecir anomalías en el conjunto de prueba
test_predictions = model.predict(x_test)
test_anomaly_scores = model.decision_function(x_test)

# Convertir predicciones a 0 (normal) y 1 (anomalía)
val_predictions = [0 if p == 1 else 1 for p in val_predictions]
test_predictions = [0 if p == 1 else 1 for p in test_predictions]

# Generar etiquetas para la matriz de confusión (0 = normal, 1 = anomalía)
val_labels = [0 if 'normal' in f else 1 for f in filenames_val]
test_labels = [0 if 'normal' in f else 1 for f in filenames_test]

# Crear y mostrar la matriz de confusión
cm = confusion_matrix(test_labels, test_predictions)
print(cm)

# Mostrar la matriz de confusión de manera más visual
df_cm = pd.DataFrame(cm, index=['normal', 'anomaly'], columns=['normal', 'anomaly'])
plt.figure()
sn.heatmap(df_cm, annot=True)
plt.title('Confusion Matrix')
plt.xlabel('Prediction')
plt.ylabel('Actual')
plt.show()

# Calcular métricas adicionales
precision = precision_score(test_labels, test_predictions)
recall = recall_score(test_labels, test_predictions)
f1 = f1_score(test_labels, test_predictions)

# Imprimir las métricas
print('Precision:', precision)
print('Recall:', recall)
print('F1 Score:', f1)

# Generar e imprimir el informe de clasificación
classification_rep = classification_report(test_labels, test_predictions, target_names=['normal', 'anomaly'])
print(classification_rep)

from joblib import dump, load

# Guardar el modelo entrenado
dump(model, 'isolation_forest_model.joblib')